{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pickle import dump, load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparamter_tuning_svm(train_features, train_labels, validation_features, validation_labels):\n",
    "    \n",
    "    parameters = {'kernel':['rbf', 'poly', 'sigmoid'], 'C':range(1, 10), 'gamma':[i * 0.1 + 0.1 for i in range(10)], 'decision_function_shape':['ovr', 'ovo']}\n",
    "    svc = svm.SVC()\n",
    "    clf = RandomizedSearchCV(svc, parameters, scoring='accuracy', verbose = 2, refit = True)\n",
    "    # clf.scorer_ = sklearn.metrics.make_scorer(accuracy_score)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    sorted(clf.cv_results_.keys())\n",
    "    y_pred = clf.predict(validation_features)\n",
    "    accuracy = accuracy_score(validation_labels, y_pred)\n",
    "    return clf.best_params_, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_Model(train_features, train_labels, validation_features, validation_labels, params):\n",
    "    # Train the SVM model\n",
    "    svc_model = SVC(kernel='poly', gamma = 1.0, C=3, decision_function_shape='ovr')\n",
    "    svc_model.fit(train_features, train_labels)\n",
    "\n",
    "    # Predict the class labels on the test set\n",
    "    y_pred = svc_model.predict(validation_features)\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    accuracy = accuracy_score(validation_labels, y_pred)\n",
    "    return accuracy, y_pred, svc_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(labels, y_pred):\n",
    "    classes = ['0', '1', '2', '3', '4', '5']\n",
    "    cm = confusion_matrix(labels, y_pred, labels=classes)\n",
    "\n",
    "    conf_matrix = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # plot the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(conf_matrix, cmap='Blues')\n",
    "\n",
    "    # set the axis labels\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(classes, fontsize=12)\n",
    "    ax.set_yticklabels(classes, fontsize=12)\n",
    "\n",
    "    # rotate the x-axis labels\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "            rotation_mode=\"anchor\")\n",
    "\n",
    "    # set the text labels in each cell\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            text = ax.text(j, i, format(conf_matrix[i, j], '.2f'),\n",
    "                        ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "    # set the plot title and show the color bar\n",
    "    ax.set_title(\"Confusion Matrix\", fontsize=16)\n",
    "    plt.colorbar(im)\n",
    "\n",
    "    # display the plot\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_weights_pickle(model, name):\n",
    "    dump(model, open(f'Models/{name}.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(train_features, train_labels, validation_features, validation_labels):\n",
    "    best_params, accuracy = hyperparamter_tuning_svm(train_features, train_labels, validation_features, validation_labels)\n",
    "    accuracy, y_pred, svc_model= SVC_Model(train_features, train_labels, validation_features, validation_labels, best_params)\n",
    "    display_confusion_matrix(validation_labels, y_pred)\n",
    "    saving_weights_pickle(svc_model, 'SVC_Model')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_py():\n",
    "    !jupyter nbconvert --to script classification_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook classification_utils.ipynb to script\n",
      "[NbConvertApp] Writing 3446 bytes to classification_utils.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    create_py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
