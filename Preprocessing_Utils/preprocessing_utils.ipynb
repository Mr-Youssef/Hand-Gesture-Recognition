{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mai\\OneDrive\\Documents\\GitHub\\Hand-Gesture-Recognition\\Preprocessing_Utils\\preprocessing_utils.ipynb Cell 2\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mai/OneDrive/Documents/GitHub/Hand-Gesture-Recognition/Preprocessing_Utils/preprocessing_utils.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mai/OneDrive/Documents/GitHub/Hand-Gesture-Recognition/Preprocessing_Utils/preprocessing_utils.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcv\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### resizing -> grayscale -> normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(img_path):\n",
    "    target_size = (200, 200)\n",
    "    # Load the image\n",
    "    image = cv.imread(img_path)\n",
    "\n",
    "    # Resize the image to the target size\n",
    "    resized_img = cv.resize(image, target_size)\n",
    "\n",
    "    # Convert the resized image to grayscale\n",
    "    gray_img = cv.cvtColor(resized_img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Normalize the pixel values to be between 0 and 1\n",
    "    # normalized_img  = gray_img / 255.0\n",
    "    normalized_img = (gray_img - np.min(gray_img)) * 255.0 / (np.max(gray_img) - np.min(gray_img))\n",
    "\n",
    "    return resized_img, gray_img, normalized_img    # return the original and the preprocessed images\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation(img):\n",
    "    # Apply Gaussian blur to remove noise (optional)\n",
    "    img = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    hsvim = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "    upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "    skinRegionHSV = cv.inRange(hsvim, lower, upper)\n",
    "    ret,thresh = cv.threshold(skinRegionHSV,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "    return thresh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphological Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_operations(img):\n",
    "    # Define the kernel for morphological operations\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "    # Perform dilation operation on the image\n",
    "    dilated_img = cv.dilate(img, kernel, iterations=1)\n",
    "\n",
    "    # Perform erosion operation on the image\n",
    "    eroded_img = cv.erode(img, kernel, iterations=1)\n",
    "\n",
    "    # Perform opening operation on the image\n",
    "    opening_img = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Perform closing operation on the image\n",
    "    closing_img = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return closing_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detection(img):\n",
    "    # Apply Gaussian blur to reduce noise in the image\n",
    "    img_blur = cv.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "    # Perform Canny edge detection\n",
    "    edges = cv.Canny(img_blur, 100, 200)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_histogram(img_edges, img_gray):\n",
    "    # Initialize number of histogram bins\n",
    "    k = 64\n",
    "    bin_width = 256 // k\n",
    "\n",
    "    # Initialize histogram bins\n",
    "    histogram = np.zeros(k, dtype=np.int32)\n",
    "\n",
    "    # Loop over every edge pixel in Iedge\n",
    "    for i in range(edges.shape[0]):\n",
    "        for j in range(edges.shape[1]):\n",
    "            # Check if the pixel is an edge pixel\n",
    "            if edges[i, j] != 0:\n",
    "                # Find corresponding gray level intensity in Igray\n",
    "                intensity = gray[i, j]\n",
    "                # Determine the bin index for the intensity\n",
    "                bin_index = intensity // bin_width\n",
    "                # Increment the count of the corresponding bin\n",
    "                histogram[bin_index] += 1\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.bar(range(k), histogram)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(images_paths):\n",
    "    imgs_edges = []\n",
    "    for img in images_paths:\n",
    "        resized, gray, norm = image_preprocessing(img)\n",
    "        segmented_img = image_segmentation(resized)\n",
    "        noise_removal = morphological_operations(segmented_img)\n",
    "        edges = canny_edge_detection(noise_removal)\n",
    "        imgs_edges.append(edges)\n",
    "    return imgs_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_py():\n",
    "    !jupyter nbconvert --to script preprocessing_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook preprocessing_utils.ipynb to script\n",
      "[NbConvertApp] Writing 2775 bytes to preprocessing_utils.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    create_py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
